import os
import json
import streamlit as st
from pathlib import Path
from PIL import Image
import base64
from io import BytesIO
import traceback
import numpy as np
import re
from config import load_config
from rag import load_documents, search_documents, ask_gemini, search_documents_with_threshold

class MultimodalRAG:
    def __init__(self, db_dir):
        self.db_dir = Path(db_dir)
        self.documents = []
        self.has_data = False
        self.load_multimodal_data()
    
    def load_multimodal_data(self):
        """Load d·ªØ li·ªáu ƒëa ph∆∞∆°ng ti·ªán t·ª´ database"""
        self.documents = []
        
        print(f"üîç Ki·ªÉm tra th∆∞ m·ª•c db: {self.db_dir.absolute()}")
        
        if not self.db_dir.exists():
            print(f"‚ùå Th∆∞ m·ª•c db kh√¥ng t·ªìn t·∫°i: {self.db_dir}")
            
            parent_dir = self.db_dir.parent
            print(f"üìÅ Th∆∞ m·ª•c cha: {parent_dir}")
            if parent_dir.exists():
                print(f"üìã N·ªôi dung th∆∞ m·ª•c cha:")
                for item in parent_dir.iterdir():
                    item_type = "üìÅ" if item.is_dir() else "üìÑ"
                    print(f"  {item_type} {item.name}")
            
            self.has_data = False
            return
            
        site_dirs = [d for d in self.db_dir.iterdir() if d.is_dir()]
        print(f"üìÅ T√¨m th·∫•y {len(site_dirs)} th∆∞ m·ª•c con trong db")
        
        for site_dir in site_dirs:
            print(f"üîç Ki·ªÉm tra th∆∞ m·ª•c: {site_dir.name}")
            
            metadata_file = site_dir / "metadata.json"
            if not metadata_file.exists():
                print(f"‚ùå Thi·∫øu metadata.json trong {site_dir.name}")
                continue
                
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                print(f"‚úÖ ƒê·ªçc metadata th√†nh c√¥ng t·ª´ {site_dir.name}")
                
                content_file = site_dir / "content.txt"
                text_content = ""
                if content_file.exists():
                    with open(content_file, 'r', encoding='utf-8') as f:
                        text_content = f.read()
                    print(f"‚úÖ ƒê·ªçc content.txt th√†nh c√¥ng ({len(text_content)} k√Ω t·ª±)")
                else:
                    print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y content.txt trong {site_dir.name}")
                
                doc = {
                    'site_name': site_dir.name,
                    'url': data['metadata']['url'],
                    'title': data['metadata']['title'],
                    'description': data['metadata']['description'],
                    'text_content': text_content,
                    'images': data.get('images', []),
                    'image_dir': site_dir / "images",
                    'metadata': data['metadata']
                }
                
                self.documents.append(doc)
                print(f"‚úÖ Th√™m document: {doc['title']}")
                
            except Exception as e:
                print(f"‚ùå L·ªói load d·ªØ li·ªáu t·ª´ {site_dir}: {e}")
                st.warning(f"L·ªói load d·ªØ li·ªáu t·ª´ {site_dir}: {e}")
        
        self.has_data = len(self.documents) > 0
        print(f"üìä T·ªïng c·ªông: {len(self.documents)} documents")
    
    def search_multimodal(self, query, threshold=0.3, top_k=3):
        """T√¨m ki·∫øm ƒëa ph∆∞∆°ng ti·ªán v·ªõi threshold"""
        if not self.has_data:
            return [], 0
            
        text_corpus = []
        for doc in self.documents:
            combined_text = f"{doc['title']}\n{doc['description']}\n{doc['text_content']}"
            
            for img in doc['images']:
                if img.get('alt'):
                    combined_text += f"\n{img['alt']}"
                if img.get('title'):
                    combined_text += f"\n{img['title']}"
            
            text_corpus.append(combined_text)
        
        try:
            relevant_texts, max_similarity = search_documents_with_threshold(
                query, text_corpus, threshold, top_k
            )
            
            relevant_docs = []
            for relevant_text in relevant_texts:
                for i, text in enumerate(text_corpus):
                    if text == relevant_text:
                        relevant_docs.append(self.documents[i])
                        break
            
            return relevant_docs, max_similarity
        except Exception as e:
            print(f"‚ùå L·ªói search: {e}")
            return [], 0
    
    def get_relevant_images_for_context(self, relevant_docs, query, max_images=5):
        """L·∫•y ·∫£nh li√™n quan ƒë·ªÉ ƒë∆∞a v√†o context cho Gemini"""
        relevant_images = []
        
        for doc in relevant_docs:
            for img_info in doc['images']:
                relevance_score = 0
                
                alt_text = img_info.get('alt', '').lower()
                title_text = img_info.get('title', '').lower()
                query_lower = query.lower()
                
                # T√≠nh ƒëi·ªÉm d·ª±a tr√™n t·ª´ kh√≥a
                for word in query_lower.split():
                    if word in alt_text or word in title_text:
                        relevance_score += 1
                
                # Bonus ƒëi·ªÉm cho ·∫£nh c√≥ m√¥ t·∫£ chi ti·∫øt
                if len(alt_text) > 20 or len(title_text) > 20:
                    relevance_score += 0.5
                
                if relevance_score > 0 or (not alt_text and not title_text):
                    img_path = Path(img_info.get('local_path', ''))
                    if img_path.exists():
                        relevant_images.append({
                            'path': img_path,
                            'alt': img_info.get('alt', ''),
                            'title': img_info.get('title', ''),
                            'url': img_info.get('url', ''),
                            'source_doc': doc,
                            'relevance_score': relevance_score
                        })
        
        relevant_images.sort(key=lambda x: x['relevance_score'], reverse=True)
        return relevant_images[:max_images]

def create_intelligent_multimodal_context(text_context, relevant_images, question):
    """T·∫°o context ƒëa ph∆∞∆°ng ti·ªán th√¥ng minh cho Gemini"""
    context = f"Th√¥ng tin vƒÉn b·∫£n:\n{text_context}\n\n"
    
    if relevant_images:
        context += "Th√¥ng tin h√¨nh ·∫£nh c√≥ s·∫µn:\n"
        for i, img_info in enumerate(relevant_images, 1):
            context += f"\n[IMAGE_{i}]:"
            if img_info['alt']:
                context += f" M√¥ t·∫£: {img_info['alt']}"
            if img_info['title']:
                context += f" Ti√™u ƒë·ªÅ: {img_info['title']}"
            context += f" (Ngu·ªìn: {img_info['source_doc']['title']})"
        
        context += f"""

QUAN TR·ªåNG: Khi tr·∫£ l·ªùi c√¢u h·ªèi "{question}", h√£y:
1. ƒê∆∞a ra c√¢u tr·∫£ l·ªùi chi ti·∫øt v√† c√≥ c·∫•u tr√∫c
2. Khi ƒë·ªÅ c·∫≠p ƒë·∫øn h√¨nh ·∫£nh, s·ª≠ d·ª•ng c√∫ ph√°p [IMAGE_X] ƒë·ªÉ ch·ªâ ƒë·ªãnh ·∫£nh n√†o c·∫ßn hi·ªÉn th·ªã
3. V√≠ d·ª•: "Nh∆∞ b·∫°n c√≥ th·ªÉ th·∫•y trong [IMAGE_1], ƒëi·ªÅu n√†y cho th·∫•y..."
4. S·ª≠ d·ª•ng [IMAGE_X] ·ªü nh·ªØng v·ªã tr√≠ ph√π h·ª£p trong c√¢u tr·∫£ l·ªùi ƒë·ªÉ minh h·ªça n·ªôi dung
5. M·ªói [IMAGE_X] s·∫Ω ƒë∆∞·ª£c thay th·∫ø b·∫±ng h√¨nh ·∫£nh t∆∞∆°ng ·ª©ng khi hi·ªÉn th·ªã

H√£y tham kh·∫£o c·∫£ th√¥ng tin vƒÉn b·∫£n v√† h√¨nh ·∫£nh ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi to√†n di·ªán v√† c√≥ minh h·ªça ph√π h·ª£p."""
    
    return context

def parse_answer_with_image_markers(answer, relevant_images):
    """Ph√¢n t√≠ch c√¢u tr·∫£ l·ªùi v√† t√°ch c√°c marker ·∫£nh"""
    # T√¨m t·∫•t c·∫£ c√°c marker [IMAGE_X]
    image_pattern = r'\[IMAGE_(\d+)\]'
    markers = re.findall(image_pattern, answer)
    
    # T√°ch c√¢u tr·∫£ l·ªùi th√†nh c√°c ph·∫ßn
    parts = re.split(image_pattern, answer)
    
    # T·∫°o danh s√°ch c√°c ph·∫ßn v·ªõi th√¥ng tin v·ªÅ ·∫£nh
    content_parts = []
    part_index = 0
    
    for i, part in enumerate(parts):
        if part.isdigit():  # ƒê√¢y l√† s·ªë c·ªßa marker ·∫£nh
            image_index = int(part) - 1  # Chuy·ªÉn t·ª´ 1-based sang 0-based
            if 0 <= image_index < len(relevant_images):
                content_parts.append({
                    'type': 'image',
                    'content': relevant_images[image_index],
                    'index': image_index
                })
        else:  # ƒê√¢y l√† text
            if part.strip():  # Ch·ªâ th√™m n·∫øu kh√¥ng ph·∫£i chu·ªói r·ªóng
                content_parts.append({
                    'type': 'text',
                    'content': part.strip()
                })
    
    return content_parts

def smart_display_answer_with_embedded_images(answer, relevant_images):
    """Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi v·ªõi ·∫£nh ƒë∆∞·ª£c ch√®n th√¥ng minh d·ª±a tr√™n AI"""
    
    if not relevant_images:
        st.markdown(answer)
        return
    
    # Ph√¢n t√≠ch c√¢u tr·∫£ l·ªùi ƒë·ªÉ t√¨m c√°c marker ·∫£nh
    content_parts = parse_answer_with_image_markers(answer, relevant_images)
    
    if not any(part['type'] == 'image' for part in content_parts):
        # N·∫øu AI kh√¥ng s·ª≠ d·ª•ng marker, fallback v·ªÅ ph∆∞∆°ng ph√°p t·ª± ƒë·ªông
        auto_embed_images_in_answer(answer, relevant_images)
        return
    
    # Hi·ªÉn th·ªã t·ª´ng ph·∫ßn
    for part in content_parts:
        if part['type'] == 'text':
            st.markdown(part['content'])
        elif part['type'] == 'image':
            img_info = part['content']
            try:
                image = Image.open(img_info['path'])
                
                # T·∫°o caption th√¥ng minh
                caption = ""
                if img_info.get('alt'):
                    caption = f"üì∑ {img_info['alt']}"
                elif img_info.get('title'):
                    caption = f"üì∑ {img_info['title']}"
                else:
                    caption = f"üì∑ H√¨nh ·∫£nh t·ª´ {img_info['source_doc']['title']}"
                
                # Hi·ªÉn th·ªã ·∫£nh v·ªõi styling ƒë·∫πp
                col1, col2, col3 = st.columns([1, 3, 1])
                with col2:
                    st.image(image, caption=caption, use_container_width=True)
                
                # Th√™m kho·∫£ng c√°ch
                st.markdown("<br>", unsafe_allow_html=True)
                
            except Exception as e:
                st.error(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã ·∫£nh: {e}")

def auto_embed_images_in_answer(answer, relevant_images):
    """T·ª± ƒë·ªông ch√®n ·∫£nh v√†o c√¢u tr·∫£ l·ªùi khi AI kh√¥ng s·ª≠ d·ª•ng marker"""
    
    # T√°ch c√¢u tr·∫£ l·ªùi th√†nh c√°c ƒëo·∫°n
    paragraphs = [p.strip() for p in answer.split('\n\n') if p.strip()]
    
    if len(paragraphs) <= 1:
        # N·∫øu ch·ªâ c√≥ 1 ƒëo·∫°n, t√°ch theo c√¢u
        sentences = [s.strip() + '.' for s in answer.split('.') if s.strip()]
        paragraphs = sentences
    
    # T√≠nh to√°n v·ªã tr√≠ ch√®n ·∫£nh
    total_parts = len(paragraphs)
    total_images = len(relevant_images)
    
    if total_images == 0:
        st.markdown(answer)
        return
    
    # T·∫°o danh s√°ch v·ªã tr√≠ ch√®n ·∫£nh
    insert_positions = []
    if total_parts > 1:
        # Ph√¢n b·ªë ƒë·ªÅu ·∫£nh trong c√¢u tr·∫£ l·ªùi
        step = max(1, total_parts // (total_images + 1))
        for i in range(min(total_images, total_parts - 1)):
            pos = (i + 1) * step
            if pos < total_parts:
                insert_positions.append(pos)
    
    # Hi·ªÉn th·ªã v·ªõi ·∫£nh ƒë∆∞·ª£c ch√®n
    image_index = 0
    for i, paragraph in enumerate(paragraphs):
        # Hi·ªÉn th·ªã ƒëo·∫°n vƒÉn
        st.markdown(paragraph)
        
        # Ch√®n ·∫£nh n·∫øu ƒë·∫øn v·ªã tr√≠ ph√π h·ª£p
        if i in insert_positions and image_index < len(relevant_images):
            img_info = relevant_images[image_index]
            
            try:
                image = Image.open(img_info['path'])
                
                # T·∫°o caption
                caption = ""
                if img_info.get('alt'):
                    caption = f"üì∑ {img_info['alt']}"
                elif img_info.get('title'):
                    caption = f"üì∑ {img_info['title']}"
                else:
                    caption = f"üì∑ H√¨nh ·∫£nh minh h·ªça"
                
                # Hi·ªÉn th·ªã ·∫£nh v·ªõi layout ƒë·∫πp
                st.markdown("<div style='text-align: center; margin: 20px 0;'>", unsafe_allow_html=True)
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    st.image(image, caption=caption, use_container_width=True)
                st.markdown("</div>", unsafe_allow_html=True)
                
                image_index += 1
                
            except Exception as e:
                st.error(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã ·∫£nh: {e}")
    
    # Hi·ªÉn th·ªã ·∫£nh c√≤n l·∫°i ·ªü cu·ªëi
    if image_index < len(relevant_images):
        st.markdown("### üñºÔ∏è H√¨nh ·∫£nh b·ªï sung")
        remaining_images = relevant_images[image_index:]
        
        cols = st.columns(min(len(remaining_images), 3))
        for i, img_info in enumerate(remaining_images):
            with cols[i % len(cols)]:
                try:
                    image = Image.open(img_info['path'])
                    st.image(image, use_container_width=True)
                    if img_info.get('alt') or img_info.get('title'):
                        st.caption(img_info.get('alt') or img_info.get('title'))
                except Exception as e:
                    st.error(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã ·∫£nh: {e}")

def ask_gemini_with_intelligent_images(question, text_context, relevant_images, api_key, model_name):
    """H·ªèi Gemini v·ªõi context th√¥ng minh bao g·ªìm h∆∞·ªõng d·∫´n ch√®n ·∫£nh"""
    try:
        # T·∫°o context v·ªõi h∆∞·ªõng d·∫´n ch√®n ·∫£nh th√¥ng minh
        intelligent_context = create_intelligent_multimodal_context(text_context, relevant_images, question)
        
        # G·ªçi Gemini v·ªõi context ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u
        response = ask_gemini(question, intelligent_context, api_key, model_name)
        
        return response, relevant_images
    except Exception as e:
        return f"Xin l·ªói, t√¥i kh√¥ng th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y. L·ªói: {e}", []

def ask_gemini_direct(question, api_key, model_name):
    """H·ªèi Gemini tr·ª±c ti·∫øp kh√¥ng c·∫ßn context"""
    try:
        return ask_gemini(question, "", api_key, model_name)
    except Exception as e:
        return f"Xin l·ªói, t√¥i kh√¥ng th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y. L·ªói: {e}"

def enhanced_search_with_fallback(rag_system, question, threshold):
    """T√¨m ki·∫øm n√¢ng cao v·ªõi fallback th√¥ng minh"""
    try:
        relevant_docs, max_similarity = rag_system.search_multimodal(question, threshold)
        
        if not relevant_docs:
            return "no_results", None, None, None, 0
        
        if max_similarity < threshold:
            return "low_relevance", None, None, None, max_similarity
        
        text_context = "\n---\n".join([
            f"Ti√™u ƒë·ªÅ: {doc['title']}\nM√¥ t·∫£: {doc['description']}\nN·ªôi dung: {doc['text_content'][:1500]}..."
            for doc in relevant_docs
        ])
        
        relevant_images = rag_system.get_relevant_images_for_context(
            relevant_docs, question, 5  # TƒÉng s·ªë ·∫£nh ƒë·ªÉ c√≥ nhi·ªÅu l·ª±a ch·ªçn
        )
        
        return "success", relevant_docs, text_context, relevant_images, max_similarity
        
    except Exception as e:
        print(f"‚ùå L·ªói trong qu√° tr√¨nh t√¨m ki·∫øm: {e}")
        return "error", None, None, None, 0

def check_database_status(db_dir):
    """Ki·ªÉm tra tr·∫°ng th√°i database v√† hi·ªÉn th·ªã th√¥ng tin debug"""
    db_path = Path(db_dir)
    
    with st.expander("üîß Th√¥ng tin Debug", expanded=False):
        st.code(f"""
Th√¥ng tin ƒë∆∞·ªùng d·∫´n:
- File app.py: {Path(__file__).absolute()}
- Th∆∞ m·ª•c src: {Path(__file__).parent.absolute()}
- Th∆∞ m·ª•c project: {Path(__file__).parent.parent.absolute()}
- Th∆∞ m·ª•c db: {db_path.absolute()}
- DB exists: {db_path.exists()}
        """)
        
        if db_path.exists():
            subdirs = [d for d in db_path.iterdir() if d.is_dir()]
            st.write(f"üìÅ S·ªë th∆∞ m·ª•c con: {len(subdirs)}")
            
            for subdir in subdirs:
                metadata_file = subdir / "metadata.json"
                content_file = subdir / "content.txt"
                images_dir = subdir / "images"
                
                st.write(f"üìÇ {subdir.name}:")
                st.write(f"  - metadata.json: {'‚úÖ' if metadata_file.exists() else '‚ùå'}")
                st.write(f"  - content.txt: {'‚úÖ' if content_file.exists() else '‚ùå'}")
                st.write(f"  - images/: {'‚úÖ' if images_dir.exists() else '‚ùå'}")

def display_search_status(search_result, relevance_score=None, threshold=None):
    """Hi·ªÉn th·ªã tr·∫°ng th√°i t√¨m ki·∫øm cho user"""
    if search_result == "success":
        st.success(f"‚úÖ T√¨m th·∫•y th√¥ng tin trong database (ƒëi·ªÉm: {relevance_score:.3f})")
    elif search_result == "no_results":
        st.info("üîç Kh√¥ng t√¨m th·∫•y th√¥ng tin trong database ‚Üí S·ª≠ d·ª•ng AI")
    elif search_result == "low_relevance":
        st.warning(f"üìä ƒê·ªô li√™n quan th·∫•p ({relevance_score:.3f} < {threshold}) ‚Üí S·ª≠ d·ª•ng AI")
    elif search_result == "error":
        st.error("‚ö†Ô∏è L·ªói t√¨m ki·∫øm ‚Üí S·ª≠ d·ª•ng AI")

def main():
    st.set_page_config(
        page_title="H·ªá th·ªëng RAG ƒêa ph∆∞∆°ng ti·ªán v·ªõi AI",
        page_icon="ü§ñ",
        layout="wide"
    )
    
    st.title("ü§ñ H·ªá th·ªëng h·ªèi ƒë√°p RAG ƒëa ph∆∞∆°ng ti·ªán v·ªõi AI")
    st.markdown("*Ch√®n ·∫£nh th√¥ng minh b·∫±ng AI v√†o c√¢u tr·∫£ l·ªùi*")
    st.markdown("---")
    
    try:
        config = load_config()
        
        # X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n db
        current_dir = Path(__file__).parent
        project_root = current_dir.parent
        db_dir = project_root / "db"
        
        check_database_status(db_dir)
        
        # Initialize multimodal RAG
        if 'multimodal_rag' not in st.session_state:
            with st.spinner("ƒêang ki·ªÉm tra d·ªØ li·ªáu..."):
                st.session_state.multimodal_rag = MultimodalRAG(str(db_dir))
        
        rag_system = st.session_state.multimodal_rag
        
        # Sidebar
        with st.sidebar:
            st.header("üìä Th√¥ng tin H·ªá th·ªëng")
            
            if rag_system.has_data:
                st.success("‚úÖ Database c√≥ d·ªØ li·ªáu")
                st.write(f"**S·ªë trang web:** {len(rag_system.documents)}")
                
                total_images = sum(len(doc['images']) for doc in rag_system.documents)
                st.write(f"**T·ªïng s·ªë ·∫£nh:** {total_images}")
                
                st.markdown("**C√°c trang web:**")
                for doc in rag_system.documents:
                    with st.expander(f"üåê {doc['title'][:50]}..."):
                        st.write(f"**URL:** {doc['url']}")
                        st.write(f"**S·ªë ·∫£nh:** {len(doc['images'])}")
                        st.write(f"**M√¥ t·∫£:** {doc['description'][:100]}...")
                        
                # Settings
                st.markdown("### ‚öôÔ∏è C√†i ƒë·∫∑t RAG")
                relevance_threshold = st.slider(
                    "Ng∆∞·ª°ng ƒë·ªô li√™n quan", 
                    0.1, 0.8, 0.3, 0.1,
                    help="N·∫øu ƒë·ªô li√™n quan th·∫•p h∆°n ng∆∞·ª°ng n√†y, h·ªá th·ªëng s·∫Ω s·ª≠ d·ª•ng AI"
                )
                max_images = st.slider("S·ªë ·∫£nh t·ªëi ƒëa", 1, 8, 5)
                show_sources = st.checkbox("Hi·ªÉn th·ªã t√†i li·ªáu ngu·ªìn", value=True)
                intelligent_embedding = st.checkbox("Ch√®n ·∫£nh th√¥ng minh b·∫±ng AI", value=True, 
                                                  help="AI s·∫Ω quy·∫øt ƒë·ªãnh v·ªã tr√≠ ch√®n ·∫£nh ph√π h·ª£p")
                
                st.markdown("### üé® T√≠nh nƒÉng AI")
                st.write("- üß† AI ph√¢n t√≠ch n·ªôi dung ƒë·ªÉ ch√®n ·∫£nh")
                st.write("- üìç X√°c ƒë·ªãnh v·ªã tr√≠ t·ªëi ∆∞u cho ·∫£nh")
                st.write("- üîÑ Fallback th√¥ng minh khi c·∫ßn")
                st.write("- üì± Responsive image layout")
            else:
                st.warning("‚ö†Ô∏è Database tr·ªëng")
                st.info("H·ªá th·ªëng s·∫Ω s·ª≠ d·ª•ng AI ƒë·ªÉ tr·∫£ l·ªùi")
                st.markdown("""
                **ƒê·ªÉ s·ª≠ d·ª•ng ch·∫ø ƒë·ªô RAG:**
                1. Ch·∫°y `collect.py` ƒë·ªÉ thu th·∫≠p d·ªØ li·ªáu
                2. ƒê·∫£m b·∫£o th∆∞ m·ª•c `db` c√≥ d·ªØ li·ªáu
                3. Kh·ªüi ƒë·ªông l·∫°i ·ª©ng d·ª•ng
                """)
                relevance_threshold = 0.3
                max_images = 5
                show_sources = True
                intelligent_embedding = True
        
        # Main interface
        st.markdown("### üí¨ ƒê·∫∑t c√¢u h·ªèi")
        question = st.text_area(
            "Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:",
            placeholder="V√≠ d·ª•: H√£y m√¥ t·∫£ chi ti·∫øt v·ªÅ c√°c s·∫£n ph·∫©m trong ·∫£nh v√† gi·∫£i th√≠ch c√°ch s·ª≠ d·ª•ng ch√∫ng..." if rag_system.has_data 
                       else "V√≠ d·ª•: H√£y gi·∫£i th√≠ch v·ªÅ tr√≠ tu·ªá nh√¢n t·∫°o v√† ·ª©ng d·ª•ng c·ªßa n√≥...",
            height=100
        )
        
        col1, col2 = st.columns([3, 1])
        with col2:
            ask_button = st.button("üöÄ H·ªèi AI", type="primary", use_container_width=True)
        
        if question and ask_button:
            if rag_system.has_data:
                # T√¨m ki·∫øm v·ªõi fallback th√¥ng minh
                search_result, relevant_docs, text_context, relevant_images, similarity_score = enhanced_search_with_fallback(
                    rag_system, question, relevance_threshold
                )
                
                # Hi·ªÉn th·ªã tr·∫°ng th√°i t√¨m ki·∫øm
                display_search_status(search_result, similarity_score, relevance_threshold)
                
                if search_result == "success":
                    # S·ª≠ d·ª•ng database v·ªõi AI th√¥ng minh
                    with st.spinner("ü§î AI ƒëang ph√¢n t√≠ch v√† t·∫°o c√¢u tr·∫£ l·ªùi v·ªõi ·∫£nh minh h·ªça..."):
                        if intelligent_embedding:
                            # S·ª≠ d·ª•ng AI ƒë·ªÉ ch√®n ·∫£nh th√¥ng minh
                            answer, images_used = ask_gemini_with_intelligent_images(
                                question,
                                text_context,
                                relevant_images[:max_images],
                                config["GEMINI_API_KEY"],
                                config["MODEL_NAME"]
                            )
                            
                            st.markdown("## üí° Tr·∫£ l·ªùi (AI + Database v·ªõi ·∫£nh th√¥ng minh)")
                            smart_display_answer_with_embedded_images(answer, images_used)
                        else:
                            # S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p t·ª± ƒë·ªông
                            answer, images_used = ask_gemini_with_intelligent_images(
                                question,
                                text_context,
                                relevant_images[:max_images],
                                config["GEMINI_API_KEY"],
                                config["MODEL_NAME"]
                            )
                            
                            st.markdown("## üí° Tr·∫£ l·ªùi (Database + ·∫£nh t·ª± ƒë·ªông)")
                            auto_embed_images_in_answer(answer, images_used)
                        
                        if show_sources:
                            with st.expander("üìö T√†i li·ªáu ngu·ªìn"):
                                for i, doc in enumerate(relevant_docs, 1):
                                    st.write(f"**{i}. {doc['title']}**")
                                    st.write(f"**URL:** {doc['url']}")
                                    st.write(f"**M√¥ t·∫£:** {doc['description']}")
                                    st.write(f"**S·ªë ·∫£nh:** {len(doc['images'])}")
                                    st.write("---")
                else:
                    # Fallback to AI
                    with st.spinner("ü§î AI ƒëang suy nghƒ©..."):
                        answer = ask_gemini_direct(
                            question, 
                            config["GEMINI_API_KEY"], 
                            config["MODEL_NAME"]
                        )
                        st.markdown("## üí° Tr·∫£ l·ªùi (t·ª´ AI)")
                        st.markdown(answer)
                        
                        if search_result == "no_results":
                            st.info("üí° C√¢u tr·∫£ l·ªùi n√†y ƒë∆∞·ª£c t·∫°o b·ªüi AI v√¨ kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong database.")
                        elif search_result == "low_relevance":
                            st.info("üí° C√¢u tr·∫£ l·ªùi n√†y ƒë∆∞·ª£c t·∫°o b·ªüi AI v√¨ th√¥ng tin trong database kh√¥ng ƒë·ªß li√™n quan.")
                        elif search_result == "error":
                            st.info("üí° C√¢u tr·∫£ l·ªùi n√†y ƒë∆∞·ª£c t·∫°o b·ªüi AI do l·ªói khi truy c·∫≠p database.")
            else:
                # Kh√¥ng c√≥ database - s·ª≠ d·ª•ng AI
                st.info("üìù S·ª≠ d·ª•ng AI ƒë·ªÉ tr·∫£ l·ªùi (kh√¥ng c√≥ database)")
                
                with st.spinner("ü§î AI ƒëang suy nghƒ©..."):
                    answer = ask_gemini_direct(
                        question, 
                        config["GEMINI_API_KEY"], 
                        config["MODEL_NAME"]
                    )
                    st.markdown("## üí° Tr·∫£ l·ªùi (t·ª´ AI)")
                    st.markdown(answer)
                    st.info("üí° ƒê·ªÉ c√≥ c√¢u tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu c·ª• th·ªÉ v·ªõi ·∫£nh minh h·ªça, h√£y thu th·∫≠p d·ªØ li·ªáu v√†o database.")
    
    except Exception as e:
        st.error(f"L·ªói kh·ªüi t·∫°o ·ª©ng d·ª•ng: {e}")
        st.code(traceback.format_exc())
        
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        ü§ñ H·ªá th·ªëng RAG ƒêa ph∆∞∆°ng ti·ªán v·ªõi AI - Ch√®n ·∫£nh th√¥ng minh
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
